<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=speech&height=300&color=gradient&customColorList=0,3,3,3,2&text=I'm%20Sooyung%20Choi!"/>
</p>

<h2 align="center">👩‍💻 Hello World — I’m a Researcher & Engineer in AI Safety</h1>

---

## 😸 About Me
- 💡 I am an LLM researcher and engineer
- 🎓 M.S. in Artificial Intelligence @ Sungkyunkwan University (2023.02 ~ 2025.02)  
- 🔥 Interested in **LLM**, **AI Safety**, **Value Alignment**, and **RAG**

## 🧠 Tech Stack
<p>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white"/>
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white"/>
  <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white"/>
</p>

## 💼 Work Experience
- **AI Intern**, Hanwha General Insurance (2025.01 ~ 2025.02)  
- **AI Intern**, Onoma AI (2022.07 ~ 2022.09)

## 🎓 Education
- Sungkyunkwan University, M.S. in **Artificial Intelligence** (2023.02 ~ 2025.02)  
- Yonsei University, B.S. in **Psychology** (2018.03 ~ 2023.02)

## 📄 Publications
### 🔹 ACL 2025 (Oral & Panel)
**Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights**  
Sooyung Choi, Jaehyeok Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak 
 [🔗 Paper](https://arxiv.org/abs/2506.06404) [💻 Code](https://github.com/Human-Language-Intelligence/Unintended-Harms-LLM)

## 🤝 Contact
- 📧 Email: swimchoi98@gmail.com  
- 🔗 LinkedIn: [linkedin.com/in/swimchoi](https://www.linkedin.com/in/swimchoi/)
