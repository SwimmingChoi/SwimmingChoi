<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=speech&height=300&color=gradient&customColorList=0,3,3,3,2&text=I'm%20Sooyung%20Choi!"/>
</p>

<h2 align="center">ğŸ‘©â€ğŸ’» Hello World â€” Iâ€™m a Researcher & Engineer in AI Safety</h1>

---

## ğŸ˜¸ About Me
- ğŸ’¡ I am an LLM researcher and engineer
- ğŸ“ M.S. in Artificial Intelligence @ Sungkyunkwan University (2023.02 ~ 2025.02)  
- ğŸ”¥ Interested in **LLM**, **AI Safety**, **Value Alignment**, and **RAG**

## ğŸ§  Tech Stack
<p>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white"/>
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white"/>
  <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white"/>
</p>

## ğŸ’¼ Work Experience
- **AI Intern**, Hanwha General Insurance (2025.01 ~ 2025.02)  
- **AI Intern**, Onoma AI (2022.07 ~ 2022.09)

## ğŸ“ Education
- Sungkyunkwan University, M.S. in **Artificial Intelligence** (2023.02 ~ 2025.02)  
- Yonsei University, B.S. in **Psychology** (2018.03 ~ 2023.02)

## ğŸ“„ Publications
### ğŸ”¹ ACL 2025 (Oral & Panel)
**Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights**  
Sooyung Choi, Jaehyeok Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak 
 [ğŸ”— Paper](https://arxiv.org/abs/2506.06404) [ğŸ’» Code](https://github.com/Human-Language-Intelligence/Unintended-Harms-LLM)

## ğŸ¤ Contact
- ğŸ“§ Email: swimchoi98@gmail.com  
- ğŸ”— LinkedIn: [linkedin.com/in/swimchoi](https://www.linkedin.com/in/swimchoi/)
